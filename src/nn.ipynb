{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06593c8a",
   "metadata": {},
   "source": [
    "# Brest Cancer Detection with PyTorch NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9365740",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "6b0e1898",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80317378",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "4f4f229c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_breast_cancer(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c00efa",
   "metadata": {},
   "source": [
    "### Split and Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "15a3435d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf718aa",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "db1d352d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.44075296, -0.43531947, -1.36208497, ...,  0.9320124 ,\n",
       "         2.09724217,  1.88645014],\n",
       "       [ 1.97409619,  1.73302577,  2.09167167, ...,  2.6989469 ,\n",
       "         1.89116053,  2.49783848],\n",
       "       [-1.39998202, -1.24962228, -1.34520926, ..., -0.97023893,\n",
       "         0.59760192,  0.0578942 ],\n",
       "       ...,\n",
       "       [ 0.04880192, -0.55500086, -0.06512547, ..., -1.23903365,\n",
       "        -0.70863864, -1.27145475],\n",
       "       [-0.03896885,  0.10207345, -0.03137406, ...,  1.05001236,\n",
       "         0.43432185,  1.21336207],\n",
       "       [-0.54860557,  0.31327591, -0.60350155, ..., -0.61102866,\n",
       "        -0.3345212 , -0.84628745]], shape=(455, 30))"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "1c4c9a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d31cb59",
   "metadata": {},
   "source": [
    "### Convert to Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "15981755",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.from_numpy(X_train).float()\n",
    "X_test_tensor = torch.from_numpy(X_test).float()\n",
    "\n",
    "y_train_tensor = torch.from_numpy(y_train).float().unsqueeze(1)\n",
    "y_test_tensor = torch.from_numpy(y_test).float().unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6c7f81",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "6b83744f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BCNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(30, 64)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.bn2 = nn.BatchNorm1d(32)\n",
    "        self.fc3 = nn.Linear(32, 16)\n",
    "        self.bn3 = nn.BatchNorm1d(16)\n",
    "        self.fc4 = nn.Linear(16, 1)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.dropout(F.leaky_relu(self.bn1(self.fc1(x)), negative_slope=0.01))\n",
    "        x = self.dropout(F.leaky_relu(self.bn2(self.fc2(x)), negative_slope=0.01))\n",
    "        x = self.dropout(F.leaky_relu(self.bn3(self.fc3(x)), negative_slope=0.01))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f94e65",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "0563a4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "FOLD 1/5\n",
      "========================================\n",
      "  Early stopping at epoch 46\n",
      "  Best Val Loss: 0.1012 | Val Accuracy: 0.9670 | Epochs: 46\n",
      "\n",
      "========================================\n",
      "FOLD 2/5\n",
      "========================================\n",
      "  Early stopping at epoch 47\n",
      "  Best Val Loss: 0.0449 | Val Accuracy: 0.9890 | Epochs: 47\n",
      "\n",
      "========================================\n",
      "FOLD 3/5\n",
      "========================================\n",
      "  Early stopping at epoch 49\n",
      "  Best Val Loss: 0.0510 | Val Accuracy: 0.9780 | Epochs: 49\n",
      "\n",
      "========================================\n",
      "FOLD 4/5\n",
      "========================================\n",
      "  Early stopping at epoch 47\n",
      "  Best Val Loss: 0.0678 | Val Accuracy: 0.9890 | Epochs: 47\n",
      "\n",
      "========================================\n",
      "FOLD 5/5\n",
      "========================================\n",
      "  Early stopping at epoch 53\n",
      "  Best Val Loss: 0.0550 | Val Accuracy: 0.9780 | Epochs: 53\n",
      "\n",
      "========================================\n",
      "K-FOLD SUMMARY\n",
      "========================================\n",
      "Fold Accuracies: ['0.9670', '0.9890', '0.9780', '0.9890', '0.9780']\n",
      "Mean Accuracy:   0.9802 ± 0.0092\n"
     ]
    }
   ],
   "source": [
    "k_folds = 5\n",
    "epochs = 100\n",
    "patience = 10\n",
    "\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(X_train_tensor)):\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"FOLD {fold+1}/{k_folds}\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    # Split data for this fold\n",
    "    X_fold_train = X_train_tensor[train_idx]\n",
    "    y_fold_train = y_train_tensor[train_idx]\n",
    "    X_fold_val = X_train_tensor[val_idx]\n",
    "    y_fold_val = y_train_tensor[val_idx]\n",
    "    \n",
    "    fold_loader = DataLoader(\n",
    "        TensorDataset(X_fold_train, y_fold_train),\n",
    "        batch_size=32, shuffle=True\n",
    "    )\n",
    "    \n",
    "    # Fresh model for each fold\n",
    "    model = BCNet()\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for x_batch, y_batch in fold_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(x_batch), y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(fold_loader)\n",
    "        train_losses.append(epoch_loss)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = criterion(model(X_fold_val), y_fold_val).item()\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            best_model_state = model.state_dict().copy()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"  Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "    # Restore best model and evaluate on fold validation set\n",
    "    model.load_state_dict(best_model_state)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_preds = torch.sigmoid(model(X_fold_val))\n",
    "        val_acc = ((val_preds >= 0.5) == y_fold_val).float().mean().item()\n",
    "    \n",
    "    fold_results.append({\n",
    "        'fold': fold + 1,\n",
    "        'val_acc': val_acc,\n",
    "        'val_loss': best_val_loss,\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'epochs_trained': len(train_losses)\n",
    "    })\n",
    "    \n",
    "    print(f\"  Best Val Loss: {best_val_loss:.4f} | Val Accuracy: {val_acc:.4f} | Epochs: {len(train_losses)}\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n{'='*40}\")\n",
    "print(\"K-FOLD SUMMARY\")\n",
    "print(f\"{'='*40}\")\n",
    "accs = [r['val_acc'] for r in fold_results]\n",
    "print(f\"Fold Accuracies: {[f'{a:.4f}' for a in accs]}\")\n",
    "print(f\"Mean Accuracy:   {sum(accs)/len(accs):.4f} ± {torch.tensor(accs).std().item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad18104",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "12d89375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training final model for 48 epochs (avg from K-Fold)\n",
      "\n",
      "Epoch 10/48, Loss: 0.2824\n",
      "Epoch 20/48, Loss: 0.1743\n",
      "Epoch 30/48, Loss: 0.1460\n",
      "Epoch 40/48, Loss: 0.1184\n"
     ]
    }
   ],
   "source": [
    "# Retrain on full training data with best hyperparameters\n",
    "final_loader = DataLoader(\n",
    "    TensorDataset(X_train_tensor, y_train_tensor),\n",
    "    batch_size=32, shuffle=True\n",
    ")\n",
    "\n",
    "final_model = BCNet()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(final_model.parameters(), lr=0.001)\n",
    "\n",
    "# Use the average epochs from K-Fold as a guide\n",
    "avg_epochs = int(sum(r['epochs_trained'] for r in fold_results) / len(fold_results))\n",
    "print(f\"Training final model for {avg_epochs} epochs (avg from K-Fold)\\n\")\n",
    "\n",
    "for epoch in range(avg_epochs):\n",
    "    final_model.train()\n",
    "    running_loss = 0.0\n",
    "    for x_batch, y_batch in final_loader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(final_model(x_batch), y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{avg_epochs}, Loss: {running_loss/len(final_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "4393c734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Loss:     0.0961\n",
      "Test Accuracy: 0.9825\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation on held-out test set\n",
    "final_model.eval()\n",
    "with torch.no_grad():\n",
    "    test_logits = final_model(X_test_tensor)\n",
    "    test_loss = criterion(test_logits, y_test_tensor).item()\n",
    "    test_preds = torch.sigmoid(test_logits)\n",
    "    test_acc = ((test_preds >= 0.5) == y_test_tensor).float().mean().item()\n",
    "\n",
    "print(f\"\\nTest Loss:     {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
